{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pdb\n",
    "import urllib.request\n",
    "from datetime import datetime\n",
    "import json\n",
    "from pathos.multiprocessing import ProcessingPool # to allow multiprocessing mapping with class functions\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScrapeCITTC():\n",
    "    \n",
    "    def __init__(self, driver_path=os.environ['CHROME_DRIVER'], max_val=100):\n",
    "        self.driver_path = driver_path\n",
    "        self.browser = webdriver.Chrome(executable_path=driver_path)\n",
    "        self.headers = {\n",
    "            \"user-agent\":\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36(KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36\"\n",
    "        }\n",
    "        self.max_val = max_val # if you want pages to load faster, reduce max val\n",
    "        \n",
    "        # requests attributes\n",
    "        self.request_schema = {\n",
    "            \"index\": \"meta_base_url\", \"title\": \"title\", \"sector\": \"sector\", \"Publish\": \"published\", \n",
    "            \"Before\": \"window\", \"Country\": \"country\", \"Description of Demand\": \"description\", \n",
    "            \"Secondary Field\": \"secondary_field\", \"Keywords\": \"keywords\", \"Mode of Co-operation\": \"cooperation_type\",\n",
    "            \"Name of Project Owner/ Holders\": \"contact_organization\", \"Organization Type\": \"contact_organization_type\",\n",
    "            \"Name\": \"contact_person\", \"Employer\": \"contact_employer\", \"Email Address\": \"contact_email\", \n",
    "            \"Telephone \": \"contact_phone\"\n",
    "        }\n",
    "        \n",
    "        # offers attributes\n",
    "        self.offer_schema = {\n",
    "            \"index\": \"meta_base_url\", \"Publish\": \"published\", \"Before\": \"window\", \"Country\": \"country\",\n",
    "            \"Region\": \"region\", \"Project Description\": \"description\", \"Secondary Field\": \"secondary_field\",\n",
    "            \"Technology Readiness Level\": \"technology_readiness_level\", \"Keywords\": \"keywords\",\n",
    "            \"Intellectual Property\": \"intellectual_property_type\", \"Filing / Grant No\": \"patent_info\",\n",
    "            \"Implementation\": \"implementation\", \"Market Prospect\": \"market_prospect\", \n",
    "            \"Mode of Co-operation\": \"cooperation_type\", \"Name of Project Owner/Holder\": \"contact_organization\",\n",
    "            \"Organization Type\": \"contact_organization_type\", \"Name\": \"contact_person\", \"Employer\": \"contact_employer\",\n",
    "            \"E-mail Address\": \"contact_email\", \"Telephone\": \"contact_phone\"\n",
    "        }\n",
    "    \n",
    "    ### retrieve all post links\n",
    "    \n",
    "    def get_total_records(self, url_formatter):\n",
    "        total_xpath = '//*[@id=\"list\"]/div/span'\n",
    "        self.browser.get(url_formatter(max_val=1))\n",
    "        total_element = self.browser.find_element_by_xpath(total_xpath)\n",
    "        total = int(total_element.get_attribute(\"innerHTML\").replace(\"&nbsp;\", \" \").split(\" \")[1])\n",
    "        print(\"Total records found: %d\" % total)\n",
    "        return total\n",
    "    \n",
    "    def get_query_links(self, url_formatter, total_records):\n",
    "        query_links = []\n",
    "        offset_val = 0\n",
    "\n",
    "        while offset_val < total_records: \n",
    "            query_links.append(url_formatter(offset_val, self.max_val))\n",
    "            offset_val += self.max_val\n",
    "\n",
    "        return query_links\n",
    "    \n",
    "    def calculate_post_range(self, total, offset):\n",
    "        if total - offset >= self.max_val:\n",
    "            return range(1, self.max_val + 1)\n",
    "        return range(1, (total - offset) + 1)\n",
    "    \n",
    "    def get_link_from_post(self, i, offer_post_xpath_formatter):\n",
    "        post_xpath = offer_post_xpath_formatter(i)\n",
    "        link_element = self.browser.find_element_by_xpath(post_xpath)\n",
    "        url = BeautifulSoup(link_element.get_attribute(\"innerHTML\"), \"lxml\").find(\"a\")[\"href\"]\n",
    "        return \"http://www.cittc.net\" + url\n",
    "    \n",
    "    def retrieve_post_links(self, url):\n",
    "        self.browser.get(url)\n",
    "        offset = int(re.search('offset=(\\d+)', url).groups()[0])\n",
    "        total_records = self.total_requests if \"demand\" in url else self.total_offers\n",
    "        post_range = self.calculate_post_range(total_records, offset)\n",
    "        return [self.get_link_from_post(i, self.format_request_post_xpath) for i in post_range]\n",
    "    \n",
    "    ### parse data from specific post\n",
    "    \n",
    "    def get_page_html(self, link):\n",
    "        page_request = urllib.request.Request(link, headers=self.headers)\n",
    "        page_html = urllib.request.urlopen(page_request).read().decode('utf-8')\n",
    "        return BeautifulSoup(page_html, \"lxml\")\n",
    "    \n",
    "    def parse_post_content(self, link):\n",
    "        detail = self.get_page_html(link)\n",
    "        row = {}\n",
    "        row[\"sector\"] = \"\".join([c for c in detail.find(\"h3\").find(\"span\").text if c.isalpha() or c.isspace()]).strip()\n",
    "        row[\"title\"] = detail.find(\"h3\")[\"title\"]\n",
    "        row.update(self.parse_info_div(detail.find(\"div\", id=\"info\")))\n",
    "        row.update(self.parse_description_div(detail))\n",
    "        row.update(self.parse_contact_div(detail.find(\"div\", id=\"contact\")))\n",
    "        return row\n",
    "\n",
    "    def get_label_content(self, label):\n",
    "        content = str(label.next_sibling)\n",
    "        if content != \"\\n\":\n",
    "            return content\n",
    "        return label.next_sibling.next_sibling.text.strip()\n",
    "    \n",
    "    def parse_info_div(self, div):\n",
    "        labels = div.find_all(\"span\")\n",
    "        content = [self.get_label_content(label) for label in labels]\n",
    "        return dict(zip([label.text.strip()[:-1] for label in labels], content))\n",
    "\n",
    "    def parse_description_div(self, detail):\n",
    "        headers = [label.text[:-1].strip() for label in detail.find(\"div\", id=\"text\").find_all(\"span\")]\n",
    "        descriptions = [desc.text.strip() for desc in detail.find_all(\"div\", class_=\"infoin word-break\")]\n",
    "        return dict(zip(headers, descriptions))\n",
    "\n",
    "    def parse_contact_div(self, div):\n",
    "        info = div.find_all(\"output\")\n",
    "        return dict(tuple(pair.text.split(\":\")) for pair in info)\n",
    "    \n",
    "    ### sanitize post data\n",
    "\n",
    "    def sanitize_keywords(self, keyword):\n",
    "        if keyword != \"No\" and pd.notnull(keyword):\n",
    "            return keyword.lower().replace(\";\", \",\").replace(\",\", \", \").replace(\"  \", \" \").replace(\" ,\", \",\")\n",
    "\n",
    "    def sanitize_title(self, title):\n",
    "        title = title.strip().replace(\"  \", \" \").replace(\"â€œ\", \"\")\n",
    "        return title\n",
    "\n",
    "    def sanitize_sector(self, sector):\n",
    "        return sector.replace(\"   \", \" \")\n",
    "\n",
    "    def add_meta_fields(self, data, category):\n",
    "        data[\"meta_organization\"] = \"CITTC\"\n",
    "        data[\"meta_category\"] = category\n",
    "        data[\"meta_collected_date\"] = datetime.now().strftime(\"%m/%d/%Y %H:%M:%S\")\n",
    "        return data\n",
    "\n",
    "    ### write\n",
    "    def write_json(self, data, file_name):\n",
    "        print(\"Writing JSON to {}\".format(file_name))\n",
    "        with open(file_name, \"w\") as f:\n",
    "            json_data = data.to_json(orient=\"records\")\n",
    "            f.write(json_data)\n",
    "            \n",
    "    def write_csv(self, data, file_name):\n",
    "        print(\"Writing CSV to {}\".format(file_name))\n",
    "        data.to_csv(file_name, index=False, encoding=\"utf-8\")\n",
    "\n",
    "    \n",
    "    ### REQUESTS\n",
    "    \n",
    "    def format_requests_url(self, offset_val=0, max_val=100):\n",
    "        return \"http://www.cittc.net/english/demandList.html?offset={}&max={}\".format(offset_val, max_val)\n",
    "    \n",
    "    def format_request_post_xpath(self, i):\n",
    "        return '//*[@id=\"list\"]/ul/li[{}]/div[6]'.format(i)\n",
    "    \n",
    "    def retrieve_requests(self):\n",
    "        print(\"REQUESTS\")\n",
    "        print(\"\\nRetrieve Total Requests\\n------------------------------\")\n",
    "        self.total_requests = self.get_total_records(self.format_requests_url)\n",
    "        \n",
    "        print(\"\\nRetrieve Request Links\\n------------------------------\")\n",
    "        query_links = self.get_query_links(self.format_requests_url, self.total_requests)\n",
    "#         request_links = ProcessingPool().amap(self.retrieve_post_links, query_links) # int error??\n",
    "        request_links = []\n",
    "        for link in query_links:\n",
    "            print(\"Processing %s\" % link)\n",
    "            request_links = request_links + self.retrieve_post_links(link)\n",
    "        \n",
    "        print(\"\\nRetrieve Content\\n------------------------------\")\n",
    "        raw_request_content = ProcessingPool().map(self.parse_post_content, request_links)\n",
    "        self.raw_requests = pd.DataFrame(raw_request_content)\n",
    "        self.raw_requests[\"meta_base_url\"] = request_links\n",
    "        print(\"{} requests parsed for content\".format(len(self.raw_requests)))\n",
    "        \n",
    "        print(\"\\nSanitize Content\\n------------------------------\")\n",
    "        self.requests = self.raw_requests.copy()\n",
    "        \n",
    "        print(\"Applying schema\")\n",
    "        self.requests.rename(columns=self.request_schema, inplace=True)\n",
    "        self.requests = self.requests[list(self.request_schema.values())]\n",
    "\n",
    "        print(\"Sanitizing values\")\n",
    "        self.requests[\"title\"] = self.requests[\"title\"].apply(self.sanitize_title)\n",
    "        self.requests[\"keywords\"] = self.requests[\"keywords\"].apply(self.sanitize_keywords)\n",
    "        self.requests[\"sector\"] = self.requests[\"sector\"].apply(self.sanitize_sector)\n",
    "        self.requests = self.add_meta_fields(self.requests, \"request\")        \n",
    "        \n",
    "        print(\"{} requests processed\".format(len(self.requests)))\n",
    "        \n",
    "    ### OFFERS\n",
    " \n",
    "    def format_offers_url(self, offset_val=0, max_val=100):\n",
    "        return \"http://www.cittc.net/english/supplyList.html?offset={}&max={}\".format(offset_val, max_val)\n",
    "    \n",
    "    def format_offer_post_xpath(self, i):\n",
    "        return '//*[@id=\"list\"]/ul/li[{}]/div[1]'.format(i)\n",
    "    \n",
    "    def retrieve_offers(self):\n",
    "        print(\"OFFERS\")\n",
    "        print(\"\\nRetrieve Total Offers\\n------------------------------\")\n",
    "        self.total_offers = self.get_total_records(self.format_offers_url)\n",
    "        \n",
    "        print(\"\\nRetrieve Offer Links\\n------------------------------\")\n",
    "        query_links = self.get_query_links(self.format_offers_url, self.total_offers)\n",
    "#         request_links = ProcessingPool().amap(self.retrieve_post_links, query_links) # int error??\n",
    "        offer_links = []\n",
    "        for link in query_links:\n",
    "            print(\"Processing %s\" % link)\n",
    "            offer_links = offer_links + self.retrieve_post_links(link)\n",
    "        \n",
    "        print(\"\\nRetrieve Content\\n------------------------------\")\n",
    "        raw_offer_content = ProcessingPool().map(self.parse_post_content, offer_links)\n",
    "        self.raw_offers = pd.DataFrame(raw_offer_content)\n",
    "        self.raw_offers[\"meta_base_url\"] = request_links\n",
    "        print(\"{} offers parsed for content\".format(len(self.raw_offers)))\n",
    "        \n",
    "        print(\"\\nSanitize Content\\n------------------------------\")\n",
    "        self.offers = self.raw_offers.copy()\n",
    "        \n",
    "        print(\"Applying schema\")\n",
    "        self.offers.rename(columns=self.offer_schema, inplace=True)\n",
    "        self.offers[list(self.offer_schema.values())]\n",
    "\n",
    "        print(\"Sanitizing values\")\n",
    "        self.offers[\"title\"] = self.offers[\"title\"].apply(self.sanitize_title)\n",
    "        self.offers[\"keywords\"] = self.offers[\"keywords\"].apply(self.sanitize_keywords)\n",
    "        self.offers[\"sector\"] = self.offers[\"sector\"].apply(self.sanitize_sector)\n",
    "        self.offers = self.add_meta_fields(self.offers, \"offer\")        \n",
    "        \n",
    "        print(\"{} offers processed\".format(len(self.offers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_scraper = ScrapeCITTC(max_val=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REQUESTS\n",
      "\n",
      "Retrieve Total Requests\n",
      "------------------------------\n",
      "Total records found: 101\n",
      "\n",
      "Retrieve Request Links\n",
      "------------------------------\n",
      "\n",
      "Retrieve Content\n",
      "------------------------------\n",
      "101 requests parsed for content\n",
      "\n",
      "Sanitize Content\n",
      "------------------------------\n",
      "Applying schema\n",
      "Sanitizing values\n",
      "101 requests processed\n"
     ]
    }
   ],
   "source": [
    "request_scraper.retrieve_requests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing JSON to cittc_requests.json\n",
      "Writing CSV to cittc_requests.csv\n"
     ]
    }
   ],
   "source": [
    "request_scraper.write_json(request_scraper.requests, \"cittc_requests.json\")\n",
    "request_scraper.write_csv(request_scraper.requests, \"cittc_requests.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OFFERS\n",
      "\n",
      "Retrieve Total Offers\n",
      "------------------------------\n",
      "Total records found: 515\n",
      "\n",
      "Retrieve Offer Links\n",
      "------------------------------\n",
      "\n",
      "Retrieve Content\n",
      "------------------------------\n",
      "515 offers parsed for content\n",
      "\n",
      "Sanitize Content\n",
      "------------------------------\n",
      "Applying schema\n",
      "Sanitizing values\n",
      "515 offers processed\n"
     ]
    }
   ],
   "source": [
    "offer_scraper = ScrapeCITTC(max_val=50)\n",
    "offer_scraper.retrieve_offers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing JSON to cittc_offers.json\n",
      "Writing CSV to cittc_offers.csv\n"
     ]
    }
   ],
   "source": [
    "offer_scraper.write_json(offer_scraper.offers, \"cittc_offers.json\")\n",
    "offer_scraper.write_csv(offer_scraper.offers, \"cittc_offers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
